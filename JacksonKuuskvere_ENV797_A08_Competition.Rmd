---
title: "TSA Competition"
author: "Aditi Jackson and Cara Kuuskvere"
date: "2024-03-28"
output: pdf_document
---

```{r setup, echo=TRUE, message=FALSE, warning=FALSE}
```

```{r setup and packages}
library(lubridate)
library(ggplot2)
library(forecast)
library(Kendall)
library(tseries)
library(outliers)
library(tidyverse)
library(smooth)
library(dplyr)
library(readr)
library(readxl)
library(zoo)
```

## Data
```{r loading data}
# loading all data
load_RAW <- read_excel("./Data/load.xlsx",col_names=TRUE,na="NA")
humidity_RAW <- read_excel("./Data/relative_humidity.xlsx",col_names=TRUE)
temperature_RAW <- read_excel("./Data/temperature.xlsx",col_names=TRUE)
```

```{r cleaning load data, echo=FALSE}
# LOAD DATA
# cleaning data in pipe
load_clean <- load_RAW %>%
  mutate(date = ymd(date)) %>%  ## create date object
  mutate(daily_average = 
           rowMeans(select(., h1:h24))) %>% 
            # transforming hourly data into daily data
  select(-h1:-h24) %>% # dropping hourly columns
  select(-meter_id)# %>% ## drop meter ID
 
load_clean$daily_average <- na.approx(load_clean$daily_average)
 #mutate(daily_average = 
           #na.approx(load_clean$daily_average)) 
            # interpolating N/A values with na.approx

# check for missing dates by creating dummy data frame for dates
Days <- as.data.frame(seq.Date(from=as.Date("2005/01/01"),
                               to=as.Date("2011/06/30"), by ="day"))
colnames(Days) <- "date"

#merge with the data with missing rows
date_check <-left_join(Days, load_clean, by="date")

# checking to ensure no N/As in load data
check_na <- is.na(date_check)
colSums(check_na) 
```

```{r cleaning humidity data, echo=FALSE}
# HUMIDITY DATA

# checking for missing values in raw data
check_na_humid <- is.na(humidity_RAW)
colSums(check_na_humid)

# cleaning data in pipe
humidity_clean <- humidity_RAW %>%
  mutate(date = ymd(date)) %>% ## create date object
  mutate(hourly_average = rowMeans(select(., rh_ws1:rh_ws28))) %>% #1 col per hour
  select(-rh_ws1:-rh_ws28) %>%  # dropping multiple obs
  mutate(hourly_average= na.approx(hourly_average)) %>% 
  pivot_wider(id_cols=date,
              names_from = hr,
              values_from = hourly_average,
              names_prefix = "h") %>% 
  mutate(daily_average = rowMeans(select(., h1:h24))) %>%# daily avg
  mutate(daily_average= na.approx(daily_average)) %>% 
  select(-h1:-h24) 

# verifying clean dataset has no N/As
check_na <- is.na(humidity_clean)
colSums(check_na) 
```

```{r cleaning temperature data, echo=FALSE}
# TEMPERATURE DATA

# checking for missing values in raw data
check_na_temp <- is.na(temperature_RAW)
colSums(check_na_temp)

# cleaning data in pipe
temperature_clean <- temperature_RAW %>%
  drop_na() %>% # dropping last row of data - contains N/As and does not have a date associated with it
  mutate(date = ymd(date)) %>% ## creating date object
  mutate(hourly_average = rowMeans(select(.,t_ws1:t_ws28))) %>% # creating hourly average 
  select(-t_ws1:-t_ws28) %>% # dropping hourly observation columns 1-28
  mutate(hourly_average= na.approx(hourly_average)) %>% # approximating N/As
  pivot_wider(id_cols=date, # making hourly rows into columns
              names_from = hr,
              values_from = hourly_average,
              names_prefix = "h") %>% 
  mutate(daily_average = rowMeans(select(., h1:h24))) %>%# daily avgerage
  mutate(daily_average= na.approx(daily_average)) %>%
  select(-h1:-h24)

# verifying clean dataset has no N/As
check_na_temp <- is.na(temperature_clean)
colSums(check_na_temp)
```

```{r train and test}
# aeparating data into values for training and testing
# training dataset starts 2005/01/01 and ends 2011/01/05
load_clean_train <- load_clean %>% 
  filter(date<"2011-06-01")

# testing dataset starts 2011/01/06 and ends 2011/06/30
load_clean_test <- load_clean %>% 
  filter(date >="2011-06-01")

```

## Time Series
```{r TS Objects}
# creating time series object for full load data
load_ts <- ts(load_clean$daily_average, start = c(2005, 1), frequency = 365)
plot(load_ts)

# creating time series object for training data
train_ts <- ts(load_clean_train$daily_average, start = c(2005, 1), frequency = 365)
plot(train_ts)

# creating time series object for testing data
test_ts <- ts(load_clean_test$daily_average, start = c(2011, 6), frequency = 365)
plot(test_ts)
```

```{r Initial plots}
# creating initial plots of time series data
# plot of TS data
TS_Plot <- 
  ggplot(load_clean, aes(x=date, y=daily_average)) +
      geom_line()
plot(TS_Plot)

# ACF and PACF plots
par(mfrow=c(1,2))
ACF_Plot <- Acf(load_clean$daily_average, lag = 40, plot = TRUE)
#ACF plot shows a slow decay which is a sign of non-stationarity
PACF_Plot <- Pacf(load_clean$daily_average, lag = 40)
#PACF plot is significant at lag 1
par(mfrow=c(1,1))

```
The initial plots show an weak exponential decay on the ACF and a strong correlation at lag 1 on the PACF. The TS plot shows at least two strong seasonal components; with seasonality within the years as well as seasonality within the months due to regular sinusoidal oscillations. 

```{r Decomposition}
# decomposing load data with R's decompose function
decompose_load <- decompose(load_ts,"additive")
plot(decompose_load)

#Creating non-seasonal residential price time series because some models can't handle seasonality
deseasonal_load <- seasadj(decompose_load)  

#decomposing training data
decompose_train <- decompose(train_ts,"additive")
plot(decompose_train)

# cannot decompose testing data because it has less than 2 periods
# decompose_test <- decompose(test_ts,"additive") 

#Creating non-seasonal residential price time series because some models can't handle seasonality
deseasonal_train <- seasadj(decompose_train)

```
Decomposed data shows an increasing trend line and a strong seasonal component from the consistent wave-like pattern. Residuals do not exhibit any clear patterns.

## Forecasting with Naive methods

```{r Model 1: Arithmetic mean on training data}
#Model 1: Arithmetic mean on training data
Model1 <- meanf(train_ts,h=30)
summary(Model1)
plot(Model1)

# Forecast using Model1 on training
forecasted_Model1 <- forecast(Model1, h = 30)

# Extract the forecasted values from training
forecast_values_Model1 <- as.numeric(forecasted_Model1$mean)

# Extract the actual values from the testing data
actual_values_Model1 <- as.numeric(test_ts)

# Compare the forecasted training values with the actual values
comparison_Model1 <- data.frame(Actual = actual_values_Model1, Forecasted = forecast_values_Model1)

#Model 1: Arithmetic mean on original data
Model1_full <- meanf(load_ts,h=30)
summary(Model1_full)

# Forecast using Model1
forecasted_Model1_full <- forecast(Model1_full, h = 30)

# Extract the forecasted values
forecast_values_Model1_full <- as.numeric(forecasted_Model1_full$mean)

# printing forecasted values
print(forecast_values_Model1_full)

```

```{r Model 2: Arithmetic mean on deseasonalized data}
# Model 2: Arithmetic mean on deseasonalized data
Model2 <- meanf(deseasonal_train, h = 30)
summary(Model2)
plot(Model2)

# Forecast using Model2 on training
forecasted_Model2 <- forecast(Model2, h = 30)

# Extract the forecasted values from training
forecast_values_Model2 <- as.numeric(forecasted_Model2$mean)

# Extract the actual values from the testing data
actual_values_Model2 <- as.numeric(test_ts)
#could not decompose the testing data since it had less than two periods, so just using testing regular

# Compare the forecasted training values with the actual values
comparison_Model2 <- data.frame(Actual = actual_values_Model2, Forecasted = forecast_values_Model2)

#Model 2: Arithmetic mean on original data
Model2_full <- meanf(load_ts,h=30)
summary(Model2_full)
#plot(Model2_full)

# Forecast using Model2
forecasted_Model2_full <- forecast(Model2_full, h = 30)

# Extract the forecasted values
forecast_values_Model2_full <- as.numeric(forecasted_Model2_full$mean)

print(forecast_values_Model2_full)
```

```{r Model 3: Arithmetic mean on original data}

#Model 3: Arithmetic mean on training data
Model3 <- meanf(train_ts,h=31)
summary(Model3)
plot(Model3)

# Forecast using Model3 on training
forecasted_Model3 <- forecast(Model3, h = 30)

# Extract the forecasted values from training
forecast_values_Model3 <- as.numeric(forecasted_Model3$mean)

# Extract the actual values from the testing data
actual_values_Model3 <- as.numeric(test_ts)

# Compare the forecasted training values with the actual values
comparison_Model3 <- data.frame(Actual = actual_values_Model3, Forecasted = forecast_values_Model3)

#Model 3: Arithmetic mean on original data
Model3_full <- meanf(load_ts,h=31)
summary(Model3_full)
plot(Model3_full)

# Forecast using Model3
forecasted_Model3_full <- forecast(Model3_full, h = 31)

# Extract the forecasted values
forecast_values_Model3_full <- as.numeric(forecasted_Model3_full$mean)

print(forecast_values_Model3_full)

```

```{r Model 4: Naive on deseasonalized data}
# Model 4: Naive on deseasonalized data
Model4 <- naive(deseasonal_train, h = 31)
summary(Model4)
plot(Model4)

# Forecast using Model4 on training
forecasted_Model4 <- forecast(Model4, h = 31)

# Extract the forecasted values from training
forecast_values_Model4 <- as.numeric(forecasted_Model4$mean)

# Extract the actual values from the testing data
actual_values_Model4 <- as.numeric(test_ts)

# Compare the forecasted training values with the actual values
#comparison_Model4 <- data.frame(Actual = actual_values_Model4, Forecasted = forecast_values_Model4)

# Forecast using Model4
forecasted_Model4_full <- forecast(deseasonal_load, h = 31)

# Extract the forecasted values
forecast_values_Model4_full <- as.numeric(forecasted_Model4_full$mean)

print(forecast_values_Model4_full)
```


```{r Model 5: Simple Average Forecasts Deseasonal}
# Model 5: Simple moving average on deseasonal data
Model5 <- sma(deseasonal_load,h=30 ,holdout = TRUE)

# Forecast using Model5 on training
forecasted_Model5 <- forecast(Model5, h = 30)

# Extract the forecasted values from training
forecast_values_Model5 <- as.numeric(forecasted_Model5$mean)

# Extract the actual values from the testing data
actual_values_Model5 <- as.numeric(test_ts)

# Compare the forecasted training values with the actual values
comparison_Model5 <- data.frame(Actual = actual_values_Model5, Forecasted = forecast_values_Model5)

# Forecast using Model5
forecasted_Model5_full <- forecast(deseasonal_load, h = 31)

# Extract the forecasted values
forecast_values_Model5_full <- as.numeric(forecasted_Model5_full$mean)

print(forecast_values_Model5_full)

```


```{r Model 6: SMA Seasonal}
# Model 6: Simple moving average on original data
Model6 <- sma(load_ts,h=30)

# Forecast using Model6 on training
forecasted_Model6 <- forecast(Model6, h = 30)

# Extract the forecasted values from training
forecast_values_Model6 <- as.numeric(forecasted_Model6$mean)

# Extract the actual values from the testing data
actual_values_Model6 <- as.numeric(test_ts)

# Forecast using Model6
forecasted_Model6_full <- forecast(load_ts, h = 31)

# Extract the forecasted values
forecast_values_Model6_full <- as.numeric(forecasted_Model6_full$mean)

print(forecast_values_Model6_full)
```

```{r Model 7: AUTO SARIMA}

# Model 7:  SARIMA on original data
Model7 <- auto.arima(train_ts)

# Forecast using Model7 on training
forecasted_Model7 <- forecast(Model7, h = 30)

# Extract the forecasted values from training
forecast_values_Model7 <- as.numeric(forecasted_Model7$mean)

# Extract the actual values from the testing data
actual_values_Model7 <- as.numeric(test_ts)

# Forecast using Model6
forecasted_Model7_full <- forecast(load_ts, h = 31)

# Extract the forecasted values
forecast_values_Model7_full <- as.numeric(forecasted_Model7_full$mean)

print(forecast_values_Model7_full)

```

```{r Model 8: Auto ARIMA on deseasonal data}
# Model 8:  ARIMA on deseasonal data
Model8 <- auto.arima(deseasonal_train, seasonal = FALSE)

# Forecast using Model8 on training
forecasted_Model8 <- forecast(Model8, h = 30)

# Extract the forecasted values from training
forecast_values_Model8 <- as.numeric(forecasted_Model8$mean)

print(forecast_values_Model8)
```

Models 6, 7 and 8 all yielded the same results. We will need to incorporate exogenous variable if we will improve our model further.

## NEURAL NETWORKS 

```{r Humidity Forecasts}
humidity_ts <- ts(humidity_clean$daily_average, start=c(2005, 1), frequency = 365)
humidity_forecast <- forecast(auto.arima(humidity_ts),h=31)
humidity_july <- as.numeric(humidity_forecast$mean)
```

```{r Model 9: NNETAR1, echo=TRUE, message=FALSE, warning=FALSE}
# Assuming humidity_clean is a dataframe with a column named
# daily_average containing humidity values

humidity_matrix <- as.matrix(humidity_clean$daily_average)
# Extract and convert to matrix

# Fit the neural network model
NN_fit <- nnetar(load_ts, p = 1, P = 0, xreg = humidity_matrix)
summary(NN_fit)
# Make forecasts using the fitted model
NN_for <- forecast(NN_fit, h = 31, xreg=humidity_july)

# Extract the forecasted values
NN_for_values <- as.numeric(NN_for$mean)

print(NN_for_values)
```

```{r Temperature Forecasts}
temperature_ts <- ts(temperature_clean$daily_average, start=c(2005, 1), frequency = 365)
temperature_forecast <- forecast(auto.arima(temperature_ts),h=31)
temperature_july <- as.numeric(temperature_forecast$mean)
```

```{r Model 10: NNETAR2, echo=TRUE, message=FALSE, warning=FALSE}
# Assuming temperature_clean is a dataframe with a column named
# daily_average containing humidity values

temperature_matrix <- as.matrix(temperature_clean$daily_average)
# Extract and convert to matrix

# Fit the neural network model
NN_fit_temp <- nnetar(load_ts, p = 1, P = 0, xreg = temperature_matrix)
summary(NN_fit_temp)

# Make forecasts using the fitted model
NN_temp_for <- forecast(NN_fit_temp, h = 31, xreg=temperature_july)

# Extract the forecasted values
NN_temp_for_values <- as.numeric(NN_temp_for$mean)

print(NN_temp_for_values)
```

```{r Model 11: NNETAR3, echo=TRUE, message=FALSE, warning=FALSE}

# Fit the neural network model using temperature and humidity 
NN_fit_temp_hum <- nnetar(load_ts, p = 1, P = 0, xreg = cbind(temperature_matrix, 
                                                              humidity_matrix))
summary(NN_fit_temp_hum)

# Make forecasts using the fitted model
NN_temp_hum_for <- forecast(NN_fit_temp_hum, h = 31, xreg = 
                              cbind(temperature_july,humidity_july))

# Extract the forecasted values
NN_temp_hum_for_values <- as.numeric(NN_temp_hum_for$mean)

print(NN_temp_hum_for_values)
```
We fit three Neural Network models: one with humidity as a regressor (NNETAR1), one with temperature as a regressor (NNETAR1), and one with both temperature and humidity as regressors (NNETAR3). Of these three, NNETAR3 produced the best forecast compared to the vanilla model. The forecast results improve by incorporating exogenous variables. We will need to try a model that can
capture the seasonal variance in humidity in temperature if we are to improve our forecast.

## TBATS
```{r Model 12: TBATs}
# TBATS can take time to fit
TBATS_fit <- tbats(load_ts, xreg=cbind(temperature_matrix, humidity_matrix))

TBATS_for <- forecast(TBATS_fit, h=31)

TBATs_values <- as.numeric(TBATS_for$mean)

print(TBATs_values)

```
The TBATS model with temperature and humidity as exogenous regressors produced the best forecast of all the models attempted.
